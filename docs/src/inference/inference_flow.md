# Inference flow

The CAIMAN-ASR server provides low-latency, real-time streaming ASR workloads behind a convenient WebSocket API.
This section describes how to set up the CAIMAN-ASR server for inference.

To use the inference you need to obtain a [license](./licensing.md), [program the FPGA](./programming_the_fpga.md) and then run the [server](./caiman-asr_server.md) docker image (or the [demo](./caiman-asr_demo.md) image for a quick start).
